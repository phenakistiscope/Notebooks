{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015bcb46-05ae-46ea-922c-221a8796efbc",
   "metadata": {
    "id": "015bcb46-05ae-46ea-922c-221a8796efbc"
   },
   "source": [
    "# Notebook pour la classification des affiches de cinéma\n",
    "\n",
    "En classifiant les images, ce Notebook permet de séparer les différents visuels des affiches de cinéma: dessins, photographies ou hybride. Au préalable 3'000 images ont été labellisées selon les trois catégories. Ensuit, différents réseaus de neurones existant et entrainé sont repris pour notre tâche. Les dernières couches de sorties sont enlevées et remplacée par une sortie vide qui permettra la prédiction de nos données.\n",
    "\n",
    "**Ce Notebook sert d'essaie aux différents modèles mis à jour dans l'état de l'art, pour le colloque Humanistica (Genève, 2022)**\n",
    "\n",
    "*Plan du Notebook*\n",
    "\n",
    "> Importer les données\n",
    "\n",
    "> Charger et appliquer le modèle\n",
    "\n",
    "> Visualiser les métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54269a-4313-4e9d-9248-e26a7b7b649c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be54269a-4313-4e9d-9248-e26a7b7b649c",
    "outputId": "94d9b011-d256-4426-b335-6b1743f2b069"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import ImageFile\n",
    "\n",
    "%pip install tensorflow_addons\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "new_rc_params = {'text.usetex': False,\n",
    "\"svg.fonttype\": 'none'\n",
    "}\n",
    "plt.rcParams.update(new_rc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312096f9-65c9-42e8-af10-ec0de372beba",
   "metadata": {
    "id": "312096f9-65c9-42e8-af10-ec0de372beba"
   },
   "source": [
    "## Importer les données\n",
    "\n",
    "Cette étape demande d'avoir, au préalable, un dossier avec les données d'entrainement et de validation chacun séparé entre les trois catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767d0e8-ab1c-4e7c-999a-1f9a5acabacc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0767d0e8-ab1c-4e7c-999a-1f9a5acabacc",
    "outputId": "f4145d7a-c9b0-4758-8d35-7db7b9695403"
   },
   "outputs": [],
   "source": [
    "# Chemins des données d'entraînement et de validation\n",
    "train_data_dir = \"\"\n",
    "validation_data_dir = \"\"\n",
    "test_data_dir = \"\"\n",
    "# les chemins sont bons?\n",
    "print(os.path.isdir(train_data_dir), os.path.isdir(test_data_dir), os.path.isdir(validation_data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdca6ec",
   "metadata": {},
   "source": [
    "### Chargement, transformation et normalisaiton \n",
    " Les arguments définissent une série de transformations aléatoires qui seront appliquées aux images générées pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f027d35-e686-4859-8fd0-8f988087cf43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f027d35-e686-4859-8fd0-8f988087cf43",
    "outputId": "439ded6f-cf70-41e8-d237-da1796acfac2"
   },
   "outputs": [],
   "source": [
    "#chargement des données\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    rotation_range=20,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52060ac6-cd0c-4bd3-a3c1-24d10aefeea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_generator.classes),\n",
    "                                        y = train_generator.classes                                                    \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(train_generator.classes), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4608fa-a468-46d5-87a6-cc1b88ce372d",
   "metadata": {
    "id": "8e4608fa-a468-46d5-87a6-cc1b88ce372d"
   },
   "source": [
    "## Chargement du modèle\n",
    "\n",
    "D'abord les modèles sont importés.  L'entrainement des couches est conservé. Seule la dernière couche est supprimée. Elle est remplacé par une couche vide qui permet de prédire trois catégories. \n",
    "\n",
    "Les modèles suivants ont été expérimentés:\n",
    "- VGG16\n",
    "- ResNet50\n",
    "- DenseNet169\n",
    "- InceptionV3\n",
    "- MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kCAkE8ZrL9nN",
   "metadata": {
    "id": "kCAkE8ZrL9nN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d11bc-c86a-4bd5-8c47-00da0d383780",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a8d11bc-c86a-4bd5-8c47-00da0d383780",
    "outputId": "4aada26f-e9ce-498c-dc42-a113fc3c065c"
   },
   "outputs": [],
   "source": [
    "# Chargement du modèle pré-entraîné\n",
    "base_model = MobileNetV2(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(224, 224, 3))\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503570e-783a-4834-834f-7701d3c48e08",
   "metadata": {
    "id": "4503570e-783a-4834-834f-7701d3c48e08"
   },
   "source": [
    "### Modification de la fin du modèle pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65d879-5082-4139-8415-0703f661adf3",
   "metadata": {
    "id": "7f65d879-5082-4139-8415-0703f661adf3"
   },
   "outputs": [],
   "source": [
    "# Ajout d'une couche d'agrégation pour réduire les dimensions des données\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e6255-25ce-4167-b882-04b4897e2480",
   "metadata": {
    "id": "da4e6255-25ce-4167-b882-04b4897e2480"
   },
   "outputs": [],
   "source": [
    "# Ajout d'une couche dense de sortie pour classer les images en trois catégories\n",
    "predictions = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12333103-3074-4da8-9883-fa26f1d1c3cb",
   "metadata": {
    "id": "12333103-3074-4da8-9883-fa26f1d1c3cb"
   },
   "outputs": [],
   "source": [
    "# Congélation des couches du modèle pré-entraîné pour ne pas les entraîner\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d7fa5-6c3d-4cc0-8838-09e4a3a847c0",
   "metadata": {
    "id": "966d7fa5-6c3d-4cc0-8838-09e4a3a847c0"
   },
   "outputs": [],
   "source": [
    "# Génération du modèle en utilisant les couches précédentes\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e077e-b1ca-42aa-9c0e-a9a5a3b89e8e",
   "metadata": {
    "id": "b08e077e-b1ca-42aa-9c0e-a9a5a3b89e8e"
   },
   "source": [
    "### Compilation et entraînement du modèle (+sauvegarde)\n",
    "\n",
    "Le modèle est ensuite compilé, avec les métriques nécessaires. Finalement il est entrainé puis sauvegardé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb40a3-b676-4c7c-918e-489154509785",
   "metadata": {
    "id": "a5eb40a3-b676-4c7c-918e-489154509785"
   },
   "outputs": [],
   "source": [
    "# Compilation du modèle en incluant différentes métriques\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64b02c-2f71-402c-878e-4e1f831756c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a64b02c-2f71-402c-878e-4e1f831756c1",
    "outputId": "367d1e15-9a57-4c8c-f480-0520e3c8aeef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a56b6-3720-4c98-b042-f5bafbfb5401",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f7a56b6-3720-4c98-b042-f5bafbfb5401",
    "outputId": "b6ac8a02-d5f5-4fba-dab0-dff8f4414df0"
   },
   "outputs": [],
   "source": [
    "# la date du jour\n",
    "\n",
    "from datetime import date\n",
    " \n",
    "today = date.today()\n",
    "today = str(today).replace(\"-\", \"\")\n",
    "today2 = today[-2:] + today[4:-2] + today[2:-4]\n",
    "print(today2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106b183-bdc8-4b8c-a878-ea07b5004a33",
   "metadata": {
    "id": "b106b183-bdc8-4b8c-a878-ea07b5004a33"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle entraîné\n",
    "nom_du_model = base_model.name+ \"_\"+ today2\n",
    "model.save('/models/model_' +nom_du_model+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a0723-7f94-432b-99d2-66721081c4d6",
   "metadata": {
    "id": "7e7a0723-7f94-432b-99d2-66721081c4d6"
   },
   "source": [
    "## Enregistrement des performances du modèle\n",
    "\n",
    "- \"Accuracy\"\n",
    "- Perte (\"Loss\")\n",
    "- Précision (\"Precision\")\n",
    "- Rappel (\"Recall\")\n",
    "- F1-score\n",
    "\n",
    "Pour comprendre, sommairement, les choix de l'algorithme, les mauvaises prédicitions sont visualisées à l'aide d'une matrice de confusion, puis directement les images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# évaluer le modèle\n",
    "\n",
    "results = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982449e-036b-480c-8def-b1fc61697c17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4982449e-036b-480c-8def-b1fc61697c17",
    "outputId": "3d64dfe5-416d-408f-983d-8cedc3b78b88"
   },
   "outputs": [],
   "source": [
    "# enregistrer\n",
    "\n",
    "# Création du dictionnaire\n",
    "data = {\n",
    "    'model': nom_du_model,\n",
    "    'test_loss': results[0],\n",
    "    'test_accuracy': results[1],\n",
    "    'test_precision': results[2],\n",
    "    'test_recall': results[3],\n",
    "    'test_f1_score': results[4],\n",
    "}\n",
    "\n",
    "# Conversion du dictionnaire en DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Enregistrement du DataFrame dans un fichier CSV\n",
    "df.to_csv(f'test_mesures_{nom_du_model}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hRu8YcSyS54n",
   "metadata": {
    "id": "hRu8YcSyS54n"
   },
   "source": [
    "### Prédire les images et visualiser les mauvaises prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6022225d-0d15-41b9-b9f8-e740d36212d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 1. Après avoir entraîné votre modèle, effectuez les prédictions sur l'ensemble de validation\n",
    "\n",
    "predicted_labels = model.predict(validation_generator)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "# 2. Collectez les vraies étiquettes pour l'ensemble de validation\n",
    "\n",
    "true_labels = validation_generator.classes\n",
    "\n",
    "# 3. Créez la matrice de confusion\n",
    "\n",
    "confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# 4. Visualisez la matrice de confusion avec un heatmap\n",
    "\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Classe Prédite')\n",
    "plt.ylabel('Classe Réelle')\n",
    "plt.title('Matrice de Confusion (DenseNet169)')\n",
    "plt.savefig(f'', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NAvPVKBAXVGH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NAvPVKBAXVGH",
    "outputId": "17ae608b-04a5-4074-c70f-962240eaa9f1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Prédire les classes pour les images de validation\n",
    "Y_pred = model.predict_generator(validation_generator, len(validation_generator))\n",
    "\n",
    "# Convertir les prédictions en étiquettes de classe\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Obtenir les noms des classes\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Obtenir les étiquettes de classe réelles\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "DYsdgNOXL0pt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DYsdgNOXL0pt",
    "outputId": "bdbcda99-1709-4a9a-ebf0-de2c47a97b24"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Obtenir les noms des fichiers d'images\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m filenames \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241m.\u001b[39mfilenames\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Identifier les images mal classées\u001b[39;00m\n\u001b[1;32m      5\u001b[0m misclassified_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_pred \u001b[38;5;241m!=\u001b[39m y_true)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Obtenir les noms des fichiers d'images\n",
    "filenames = validation_generator.filenames\n",
    "\n",
    "# Identifier les images mal classées\n",
    "misclassified_indices = np.where(y_pred != y_true)[0]\n",
    "\n",
    "# Visualiser les images mal classées\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "\n",
    "for i, index in enumerate(misclassified_indices[:4]):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    img = plt.imread(validation_data_dir + '/' + filenames[index])\n",
    "    axs[row][col].imshow(img)\n",
    "    axs[row][col].set_title(f\"Vraie classe : {class_names[y_true[index]]}\\nClasse prédite : {class_names[y_pred[index]]}\")\n",
    "    axs[row][col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"misclassified_{nom_du_model}.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed345f-9a2b-4515-acf5-fcfe677bf154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
