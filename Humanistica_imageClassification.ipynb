{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015bcb46-05ae-46ea-922c-221a8796efbc",
   "metadata": {
    "id": "015bcb46-05ae-46ea-922c-221a8796efbc"
   },
   "source": [
    "# Notebook pour la classification des affiches de cinéma\n",
    "\n",
    "En classifiant les images, ce Notebook permet de séparer les différents visuels des affiches de cinéma: dessins, photographies ou hybride. Au préalable 3'000 images ont été labellisées selon les trois catégories. Ensuit, différents réseaus de neurones existant et entrainé sont repris pour notre tâche. Les dernières couches de sorties sont enlevées et remplacée par une sortie vide qui permettra la prédiction de nos données.\n",
    "\n",
    "**Ce Notebook sert d'essaie aux différents modèles mis à jour dans l'état de l'art, pour le colloque Humanistica (Genève, 2022)**\n",
    "\n",
    "*Plan du Notebook*\n",
    "\n",
    "> Importer les données\n",
    "\n",
    "> Charger et appliquer le modèle\n",
    "\n",
    "> Visualiser les métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54269a-4313-4e9d-9248-e26a7b7b649c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be54269a-4313-4e9d-9248-e26a7b7b649c",
    "outputId": "94d9b011-d256-4426-b335-6b1743f2b069"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import ImageFile\n",
    "\n",
    "%pip install tensorflow_addons\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "new_rc_params = {'text.usetex': False,\n",
    "\"svg.fonttype\": 'none'\n",
    "}\n",
    "plt.rcParams.update(new_rc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312096f9-65c9-42e8-af10-ec0de372beba",
   "metadata": {
    "id": "312096f9-65c9-42e8-af10-ec0de372beba"
   },
   "source": [
    "## Importer les données\n",
    "\n",
    "Cette étape demande d'avoir, au préalable, un dossier avec les données d'entrainement et de validation chacun séparé entre les trois catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767d0e8-ab1c-4e7c-999a-1f9a5acabacc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0767d0e8-ab1c-4e7c-999a-1f9a5acabacc",
    "outputId": "f4145d7a-c9b0-4758-8d35-7db7b9695403"
   },
   "outputs": [],
   "source": [
    "# Chemins des données d'entraînement et de validation\n",
    "train_data_dir = \"\"\n",
    "validation_data_dir = \"\"\n",
    "# les chemins sont bons?\n",
    "print(os.path.isdir(train_data_dir), os.path.isdir(validation_data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdca6ec",
   "metadata": {},
   "source": [
    "### Chargement, transformation et normalisaiton \n",
    " Les arguments définissent une série de transformations aléatoires qui seront appliquées aux images générées pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f027d35-e686-4859-8fd0-8f988087cf43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f027d35-e686-4859-8fd0-8f988087cf43",
    "outputId": "439ded6f-cf70-41e8-d237-da1796acfac2"
   },
   "outputs": [],
   "source": [
    "# chargement, transformation et normalisaiton \n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                             shear_range=0.2, \n",
    "                                                             zoom_range=0.2, \n",
    "                                                             width_shift_range=0.2,\n",
    "                                                             height_shift_range=0.2,\n",
    "                                                             horizontal_flip=True, \n",
    "                                                             rotation_range=20,\n",
    "                                                             fill_mode=\"nearest\")\n",
    "val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4608fa-a468-46d5-87a6-cc1b88ce372d",
   "metadata": {
    "id": "8e4608fa-a468-46d5-87a6-cc1b88ce372d"
   },
   "source": [
    "## Chargement du modèle\n",
    "\n",
    "D'abord les modèles sont importés.  L'entrainement des couches est conservé. Seule la dernière couche est supprimée. Elle est remplacé par une couche vide qui permet de prédire trois catégories. \n",
    "\n",
    "Les modèles suivants ont été expérimentés:\n",
    "- VGG16\n",
    "- ResNet50\n",
    "- DenseNet169\n",
    "- InceptionV3\n",
    "- MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kCAkE8ZrL9nN",
   "metadata": {
    "id": "kCAkE8ZrL9nN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d11bc-c86a-4bd5-8c47-00da0d383780",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a8d11bc-c86a-4bd5-8c47-00da0d383780",
    "outputId": "4aada26f-e9ce-498c-dc42-a113fc3c065c"
   },
   "outputs": [],
   "source": [
    "# Chargement du modèle pré-entraîné\n",
    "base_model = MobileNetV2(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(224, 224, 3))\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503570e-783a-4834-834f-7701d3c48e08",
   "metadata": {
    "id": "4503570e-783a-4834-834f-7701d3c48e08"
   },
   "source": [
    "### Modification de la fin du modèle pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65d879-5082-4139-8415-0703f661adf3",
   "metadata": {
    "id": "7f65d879-5082-4139-8415-0703f661adf3"
   },
   "outputs": [],
   "source": [
    "# Ajout d'une couche d'agrégation pour réduire les dimensions des données\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e6255-25ce-4167-b882-04b4897e2480",
   "metadata": {
    "id": "da4e6255-25ce-4167-b882-04b4897e2480"
   },
   "outputs": [],
   "source": [
    "# Ajout d'une couche dense de sortie pour classer les images en trois catégories\n",
    "predictions = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12333103-3074-4da8-9883-fa26f1d1c3cb",
   "metadata": {
    "id": "12333103-3074-4da8-9883-fa26f1d1c3cb"
   },
   "outputs": [],
   "source": [
    "# Congélation des couches du modèle pré-entraîné pour ne pas les entraîner\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d7fa5-6c3d-4cc0-8838-09e4a3a847c0",
   "metadata": {
    "id": "966d7fa5-6c3d-4cc0-8838-09e4a3a847c0"
   },
   "outputs": [],
   "source": [
    "# Génération du modèle en utilisant les couches précédentes\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e077e-b1ca-42aa-9c0e-a9a5a3b89e8e",
   "metadata": {
    "id": "b08e077e-b1ca-42aa-9c0e-a9a5a3b89e8e"
   },
   "source": [
    "### Compilation et entraînement du modèle (+sauvegarde)\n",
    "\n",
    "Le modèle est ensuite compilé, avec les métriques nécessaires. Finalement il est entrainé puis sauvegardé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb40a3-b676-4c7c-918e-489154509785",
   "metadata": {
    "id": "a5eb40a3-b676-4c7c-918e-489154509785"
   },
   "outputs": [],
   "source": [
    "# Compilation du modèle en incluant différentes métriques\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', Precision(), Recall(), F1Score(num_classes=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64b02c-2f71-402c-878e-4e1f831756c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a64b02c-2f71-402c-878e-4e1f831756c1",
    "outputId": "367d1e15-9a57-4c8c-f480-0520e3c8aeef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=74,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a56b6-3720-4c98-b042-f5bafbfb5401",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f7a56b6-3720-4c98-b042-f5bafbfb5401",
    "outputId": "b6ac8a02-d5f5-4fba-dab0-dff8f4414df0"
   },
   "outputs": [],
   "source": [
    "# la date du jour\n",
    "\n",
    "from datetime import date\n",
    " \n",
    "today = date.today()\n",
    "today = str(today).replace(\"-\", \"\")\n",
    "today2 = today[-2:] + today[4:-2] + today[2:-4]\n",
    "print(today2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106b183-bdc8-4b8c-a878-ea07b5004a33",
   "metadata": {
    "id": "b106b183-bdc8-4b8c-a878-ea07b5004a33"
   },
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle entraîné\n",
    "nom_du_model = base_model.name+ \"_\"+ today2\n",
    "model.save('/models/model_' +nom_du_model+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hXmWd5bJv0AH",
   "metadata": {
    "id": "hXmWd5bJv0AH"
   },
   "outputs": [],
   "source": [
    "# Enregistrer les métriques dans un CSV\n",
    "import pandas as pd\n",
    "\n",
    "# créer un dataframe pandas avec les mesures\n",
    "df = pd.DataFrame(history.history)\n",
    "df.columns = [\"loss\",\"accuracy\",\"precision\",\"recall\",\"f1_score\",\"val_loss\",\"val_accuracy\",\"val_precision\",\"val_recall\",\"val_f1_score\"]\n",
    "df[\"model\"] = nom_du_model\n",
    "\n",
    "# enregistrer le dataframe dans un fichier CSV\n",
    "df.to_csv(f'/metrics/mesures_{nom_du_model}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a0723-7f94-432b-99d2-66721081c4d6",
   "metadata": {
    "id": "7e7a0723-7f94-432b-99d2-66721081c4d6"
   },
   "source": [
    "## Visualisations des performances du modèle\n",
    "\n",
    "Les métriques sont d'abord visualisées et enregistrées séparéement. Dans un second temps, elles sont visualisée ensemble. \n",
    "\n",
    "- \"Accuracy\"\n",
    "- Perte (\"Loss\")\n",
    "- Précision (\"Precision\")\n",
    "- Rappel (\"Recall\")\n",
    "\n",
    "Pour comprendre, sommairement, les choix de l'algorithme, les mauvaises prédicitions sont visualisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy et loss pour l'entrainement et la validation du modèle\n",
    "\n",
    "fig = plt.figure(figsize=(15,12))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(221)\n",
    "plt.plot(history.history['accuracy'],'bo--', label = \"train\")\n",
    "plt.plot(history.history['val_accuracy'], 'ro--', label = \"validation\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss function\n",
    "plt.subplot(222)\n",
    "plt.plot(history.history['loss'],'bo--', label = \"train\")\n",
    "plt.plot(history.history['val_loss'], 'ro--', label = \"validation\")\n",
    "plt.title(\"Loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "\n",
    "plt.legend()\n",
    "#plt.show()\n",
    "plt.savefig(f\"/content/drive/MyDrive/visualisations/acc_loss_{nom_du_model}.svg\")\n",
    "plt.savefig(f\"/content/drive/MyDrive/visualisations/acc_loss_{nom_du_model}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982449e-036b-480c-8def-b1fc61697c17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4982449e-036b-480c-8def-b1fc61697c17",
    "outputId": "3d64dfe5-416d-408f-983d-8cedc3b78b88"
   },
   "outputs": [],
   "source": [
    "# Visualisation de l'historique de l'entraînement\n",
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "recall = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "\n",
    "# Visualisation de la précision\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(epochs_range, precision,'o--', color=\"green\",label='Precision entraînement')\n",
    "plt.plot(epochs_range, val_precision,'o--',color=\"pink\", label='Precision validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Précision')\n",
    "\n",
    "# Visualisation du recall\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(epochs_range , recall, 'o--',color=\"green\", label='Recall entraînement')\n",
    "plt.plot(epochs_range, val_recall,'o--',color=\"pink\", label='Recall validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Recall')\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(f\"/content/drive/MyDrive/visualisations/metriques_{nom_du_model}.svg\")\n",
    "plt.savefig(f\"/content/drive/MyDrive/visualisations/metriques_{nom_du_model}.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hRu8YcSyS54n",
   "metadata": {
    "id": "hRu8YcSyS54n"
   },
   "source": [
    "### Prédire les images et visualiser les mauvaises prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NAvPVKBAXVGH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NAvPVKBAXVGH",
    "outputId": "17ae608b-04a5-4074-c70f-962240eaa9f1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Prédire les classes pour les images de validation\n",
    "Y_pred = model.predict_generator(validation_generator, len(validation_generator))\n",
    "\n",
    "# Convertir les prédictions en étiquettes de classe\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# Obtenir les noms des classes\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Obtenir les étiquettes de classe réelles\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mnjxs_rhRb1f",
   "metadata": {
    "id": "Mnjxs_rhRb1f"
   },
   "outputs": [],
   "source": [
    "# enregistrer le rapport de classification\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "dfr = pd.DataFrame(report).transpose()\n",
    "dfr.to_csv(f'/rapport/rapport_{nom_du_model}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DYsdgNOXL0pt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DYsdgNOXL0pt",
    "outputId": "bdbcda99-1709-4a9a-ebf0-de2c47a97b24"
   },
   "outputs": [],
   "source": [
    "# Obtenir les noms des fichiers d'images\n",
    "filenames = validation_generator.filenames\n",
    "\n",
    "# Identifier les images mal classées\n",
    "misclassified_indices = np.where(y_pred != y_true)[0]\n",
    "\n",
    "# Visualiser les images mal classées\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "\n",
    "for i, index in enumerate(misclassified_indices[:4]):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    img = plt.imread(validation_data_dir + '/' + filenames[index])\n",
    "    axs[row][col].imshow(img)\n",
    "    axs[row][col].set_title(f\"Vraie classe : {class_names[y_true[index]]}\\nClasse prédite : {class_names[y_pred[index]]}\")\n",
    "    axs[row][col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/content/drive/MyDrive/visualisations/misclassified_{nom_du_model}.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6CwHjnRPizd8",
   "metadata": {
    "id": "6CwHjnRPizd8"
   },
   "source": [
    "### Importer et visualiser toutes les métriques dans un graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hEPFIk9mi269",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hEPFIk9mi269",
    "outputId": "5cbf90b8-4886-4b35-d51e-b8257a0c219a"
   },
   "outputs": [],
   "source": [
    "# Définir les noms des fichiers CSV à charger\n",
    "directory = '/metrics/'\n",
    "csv_files = os.listdir(directory)\n",
    "\n",
    "# Initialiser une liste pour stocker les dataframes pandas chargés à partir des fichiers CSV\n",
    "dfs = []\n",
    "\n",
    "# Charger chaque fichier CSV en tant que dataframe pandas et l'ajouter à la liste\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(directory,csv_file))\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "# Parcourir chaque dataframe dans la liste et créer un graphique pour chaque métrique\n",
    "for col in [\"loss\", \"accuracy\", \"precision\", \"recall\", \"f1_score\"]:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Parcourir chaque dataframe dans la liste et tracer la courbe de la métrique souhaitée\n",
    "    for df in dfs:\n",
    "        ax.plot(df.index, df[col], label=df[\"model\"][0])\n",
    "\n",
    "    # Définir les étiquettes des axes, le titre et la légende\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(col.capitalize())\n",
    "    ax.set_title(f\"{col.capitalize()} over Epochs\")\n",
    "    ax.legend(loc='upper right', prop={'size': 8})\n",
    "\n",
    "    # Enregistrer le graphique avec le nom de la métrique et la date du jour\n",
    "    plt.savefig(f\"/visualisations/allModels_{col}_{today2}.png\")\n",
    "\n",
    "    # Afficher le graphique\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
